{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJEOoWfIMyRO"
      },
      "outputs": [],
      "source": [
        "# code for converting bddk100 into custom\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define directory path\n",
        "dir_path = \"/content/drive/MyDrive/lane_d/Target_dataset/train\"\n",
        "i=1;\n",
        "# Loop through files in directory\n",
        "for file_name in os.listdir(dir_path):\n",
        "    # Check if file is a regular file (not a directory)\n",
        "    if os.path.isfile(os.path.join(dir_path, file_name)):\n",
        "        # Do something with file (e.g. print its name)\n",
        "        \n",
        "         print(i)\n",
        "         i+=1\n",
        "         # Load image\n",
        "         img = Image.open(dir_path+'/'+file_name)\n",
        "         rgb = img.convert('RGB')\n",
        "         # Define list of colors to keep\n",
        "         keep_colors = [(0,0,142),(0,0,7),(128,64,128)]  # Example colors\n",
        "         # Loop through each pixel and change color if needed\n",
        "         for y in range(rgb.height):\n",
        "             for x in range(rgb.width):\n",
        "                 pixel_color = rgb.getpixel((x, y))\n",
        "                 if pixel_color not in keep_colors:\n",
        "                     rgb.putpixel((x, y), (0,0,0))  # Change color to black\n",
        "\n",
        "\n",
        "        \n",
        "         new_image_path=os.path.join('/content/drive/MyDrive/lane_d/target_dataset_1/train',file_name)\n",
        "         rgb.save(new_image_path) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KJoyxI7SU4-"
      },
      "outputs": [],
      "source": [
        "# dataset unzip from drive\n",
        "!unzip /content/drive/MyDrive/lane_d.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJmVSLK9UBjN",
        "outputId": "889717c6-253e-4666-e3db-1315c6c5635a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/lane_d/target_dataset_1/train/fee92217-63b3f87f_train_color.png\n",
            "/content/lane_d/target_dataset_1/train/ff1e4d6d-f4d85cfd_train_color.png\n",
            "/content/lane_d/target_dataset_1/train/ff3d3536-04986e25_train_color.png\n",
            "/content/lane_d/target_dataset_1/train/ff3da814-c3463a43_train_color.png\n"
          ]
        }
      ],
      "source": [
        "# removing file without target image\n",
        "import os\n",
        "import tensorflow as tf\n",
        "image_files = sorted([os.path.join(\"/content/lane_d/target_dataset_1/train\", file) for file in os.listdir('/content/lane_d/target_dataset_1/train') if file.endswith('_train_color.png')])\n",
        "for img in image_files :\n",
        "    file_name = tf.strings.regex_replace(img, '_train_color.png', '.jpg').numpy().decode()\n",
        "    if  tf.io.gfile.exists(file_name) == False :\n",
        "            os.remove(img)\n",
        "            print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87BFhLX74T00",
        "outputId": "2c1e13e8-1057-47ec-89a0-6f7bec77d70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/lane_d/target_dataset_1/val/97b65dd9-48538198_train_color.png\n"
          ]
        }
      ],
      "source": [
        "\n",
        "image_files = sorted([os.path.join(\"/content/lane_d/target_dataset_1/val\", file) for file in os.listdir('/content/lane_d/target_dataset_1/val') if file.endswith('_train_color.png')])\n",
        "for img in image_files :\n",
        "    file_name = tf.strings.regex_replace(img, '_train_color.png', '.jpg').numpy().decode()\n",
        "    if  tf.io.gfile.exists(file_name) == False :\n",
        "            os.remove(img)\n",
        "            print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BsLEAow7SmeL"
      },
      "outputs": [],
      "source": [
        "# input pipiline\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(root_dir) if  f.endswith(\"_train_color.png\")]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        target_name = self.image_files[idx]\n",
        "        img_name = target_name.replace(\"_train_color.png\", \".jpg\")\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "        target_path = os.path.join(self.root_dir, target_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        target = Image.open(target_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            target = self.transform(target)\n",
        "        return img, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mDRnoGAPSrQQ"
      },
      "outputs": [],
      "source": [
        "# creating dataloder\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Lambda(lambda x: x / 255)\n",
        "])\n",
        "dataset = CustomDataset(\"/content/lane_d/target_dataset_1/train\", transform=transform)\n",
        "val_dataset = CustomDataset(\"/content/lane_d/target_dataset_1/val\", transform=transform)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset,batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "O9f8Yq7HSu3H"
      },
      "outputs": [],
      "source": [
        "#architecture implementation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Down part of the network\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Up part of the network\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n",
        "            self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        # Downward path\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Upward path\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip_connection = skip_connections[-(idx//2+1)]\n",
        "            x = torch.cat([x, skip_connection], dim=1)\n",
        "            x = self.ups[idx+1](x)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "w0DLv_IFSwpS"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PQNpDiyTS0j4"
      },
      "outputs": [],
      "source": [
        "model = UNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "mza2l77YS2UC"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "qGZOl1a0Vcrp"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qfR7Dlm6S5dO"
      },
      "outputs": [],
      "source": [
        "# loss function\n",
        "def combined_loss(y_pred, y_true):\n",
        "    ce_loss = F.cross_entropy(y_pred, y_true)\n",
        "    mse_loss = F.mse_loss(y_pred, y_true)\n",
        "    return ce_loss + 0.1* mse_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftBS9hZK2OKp",
        "outputId": "bb4ac591-8685-4969-94c5-5f6781eba5c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load trained model\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/light_unet_lane_detection_last_epoch.pt',map_location=torch.device('cpu')),strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKWhyfvIS6nW",
        "outputId": "cd21b0bc-a6bb-4e3c-ea07-1281e97995cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, batch 100: loss 0.3058\n",
            "val_loss : 0.30661216378211975\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    # Train the model\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        # Get the inputs and move them to the GPU\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = combined_loss(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics and log to TensorBoard\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f\"Epoch {epoch + 1}, batch {i + 1}: loss {running_loss / 100:.4f}\")\n",
        "\n",
        "            running_loss = 0.0\n",
        "            v_losses = 0\n",
        "            for val_batch in val_dataloader :\n",
        "              v_inputs,v_labels = val_batch\n",
        "              v_inputs = v_inputs.to(device)\n",
        "              v_labels = v_labels.to(device)\n",
        "              v_outputs = model(v_inputs)\n",
        "              v_loss = combined_loss(v_outputs,v_labels)\n",
        "              v_losses += v_loss.item()\n",
        "              break\n",
        "            print(f'val_loss : {v_losses}')\n",
        "    # Save the model checkpoint\n",
        "    torch.save(model.state_dict(), f\"/content/drive/MyDrive/kaggle/light_unet_lane_detection_last_epoch.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYR53xwn3s79",
        "outputId": "09ef18f4-59e8-4149-934c-d9debacbd4a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NIUGMCI7hLsd"
      },
      "outputs": [],
      "source": [
        "#save ground truth,input,output\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "save_path='/content/drive/MyDrive/result_1';\n",
        "\n",
        "\n",
        "# Iterate over the validation dataset and make predictions\n",
        "for i, (inputs,_) in enumerate(test_dataloader):\n",
        "    # Pass the inputs through the model\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # Save the input and output images\n",
        "    for j in range(len(inputs)):\n",
        "        # input_image.save(os.path.join(save_path, f'input_{i}.jpg'))\n",
        "        torchvision.utils.save_image(inputs[j], os.path.join(save_path, f'input_{i * len(inputs) + j}.png'))\n",
        "        torchvision.utils.save_image(outputs[j],  os.path.join(save_path,f'output_{i * len(inputs) + j}.png'))\n",
        "        torchvision.utils.save_image(labels[j],  os.path.join(save_path,f'label_{i * len(inputs) + j}.png'))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu3yv3HeoajV"
      },
      "outputs": [],
      "source": [
        "# unzip test data from drive\n",
        "!unzip /content/drive/MyDrive/test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "H2mN6qm180Is"
      },
      "outputs": [],
      "source": [
        "# Testing code\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Define the transforms to be applied to the input image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load the input image\n",
        "\n",
        "input_dir = '/content/test'\n",
        "output_dir = '/content/drive/MyDrive/result_2'\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        # Load the input image\n",
        "        image_path = os.path.join(input_dir, filename)\n",
        "        input_image = Image.open(input_path).convert('RGB')\n",
        "\n",
        "        # Apply the transforms to the input image\n",
        "        input_tensor = transform(input_image).unsqueeze(0)\n",
        "\n",
        "        # Apply the model to the input tensor\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "\n",
        "        # Convert the output tensor to an image\n",
        "        output_image = transforms.ToPILImage()(output.squeeze(0))\n",
        "\n",
        "# Define the output path and save the output image to that directory\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "        output_image.save(output_path)\n",
        "        "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
